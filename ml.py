# -*- coding: utf-8 -*-
"""ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RNLQXphmIWjmtyGzFdi9J0-1wl8Z6o4w

## Regression
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

df = pd.read_csv('ComputerHardware.csv')

df.head(10)

df.isna().sum()

plt.scatter(df['MMAX'],df['PRP'])
plt.xlabel('MMAX')
plt.ylabel('PRP')
plt.show()

sns.pairplot(df)

X = df[['MMAX']]
y = df[['PRP']]

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)

lr = LinearRegression()
lr.fit(X_train,y_train)
lr

print('Intercept: ', lr.intercept_)
print('Coef: ', lr.coef_)

y_pred = lr.predict(X_test)
prp = pd.DataFrame({'Actual PRP':y_test.values.flatten(),'Predicted PRP':y_pred.flatten()})
prp

from sklearn import metrics

print("Mean Squared Error: ",metrics.mean_squared_error(y_test,y_pred))
print("Mean Absolute Error: ",metrics.mean_absolute_error(y_test,y_pred))
print("Root Mean Squared Error: ",np.sqrt(metrics.mean_squared_error(y_test,y_pred)))

df2 = df.copy()

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
df2['VendorName'] = label_encoder.fit_transform(df2['VendorName'])
df2['ModelName'] = label_encoder.fit_transform(df2['ModelName'])

X = df2.drop(columns=['PRP'])
y = df2[['PRP']]

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)

lr = LinearRegression()
model_mr = lr.fit(X_train,y_train)
model_mr

y_pred = model_mr.predict(X_test)

prp = pd.DataFrame({'Actual PRP':y_test.values.flatten(),'Predicted PRP':y_pred.flatten()})
prp

print("Mean Absolute Error: ",metrics.mean_absolute_error(y_test,y_pred))
print("Mean Squared Error: ",metrics.mean_squared_error(y_test,y_pred))
print("Root Mean Squared Error: ",np.sqrt(metrics.mean_absolute_error(y_test,y_pred)))

"""## Logistic Regression and NB"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
import seaborn as sns
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_curve,auc,confusion_matrix

df = pd.read_csv('framingham.csv')

df.head(10)

df.isna().sum()

df = df.dropna()

sns.pairplot(df,hue='TenYearCHD')

X = df.drop(columns=['TenYearCHD'])
y = df[['TenYearCHD']]
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)

lr = LogisticRegression()
lr.fit(X_train,y_train)
lr

nb = GaussianNB()
nb.fit(X_train,y_train)

y_pred_lr = lr.predict(X_test)
y_pred_nb = nb.predict(X_test)

## Accuracy

def evaluate(classifier,y_pred,y_test):
    print("Accuracy: ",accuracy_score(y_pred,y_test))
    print("Precision: ",precision_score(y_pred,y_test,average='weighted'))
    print("Recall: ",recall_score(y_pred,y_test,average='weighted'))
    print("F1 Score: ",f1_score(y_pred,y_test,average='weighted'))

print("********Logistic Regression********")
evaluate(lr,y_pred_lr,y_test)

print("********Naive Bayes********")
evaluate(nb,y_pred_nb,y_test)

def plot_cm(model_name,y_pred,y_test):
    classes = [0,1]
    cm = confusion_matrix(y_test,y_pred)
    plt.imshow(cm,interpolation='nearest',cmap=plt.cm.Blues)
    plt.title(model_name)
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks,classes)
    plt.yticks(tick_marks,classes)
    plt.colorbar()
    plt.ylabel('True Labels')
    plt.xlabel('Predicted Labels')

plot_cm('Naive Bayes',y_pred_nb,y_test)

plot_cm('Logistic Regression',y_pred_lr,y_test)

"""## DecisionTree"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import *
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import plot_tree
from sklearn.model_selection import train_test_split
import seaborn as sns

df = pd.read_csv('Wine_dataset.csv')
df.tail(10)

sns.pairplot(df,hue='class')

sns.countplot(x='class',data=df)

X = df.drop(columns=['class'])
y = df['class']
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)

sns.boxplot(X)

id3 = DecisionTreeClassifier(criterion='entropy',random_state=42)
id3.fit(X_train,y_train)
plt.figure(figsize=(20, 10))
plot_tree(id3,feature_names=X_train.columns.tolist(),class_names=['1','2','3'],filled=True)

y_pred_id3 = id3.predict(X_test)
preds = pd.DataFrame({'Actual Class':y_test.values.flatten(),'Predicted Class':y_pred_id3.flatten()})
preds

print('Metrics\n')
accuracy_id3 = accuracy_score(y_test, y_pred_id3)
precision_id3 = precision_score(y_test, y_pred_id3, average='weighted')
recall_id3 = recall_score(y_test, y_pred_id3, average='weighted')
f1_id3 = f1_score(y_test, y_pred_id3, average='weighted')
print("Accuracy:", accuracy_id3)
print("Precision:", precision_id3)
print("Recall:", recall_id3)
print("F1 Score:", f1_id3)

cart = DecisionTreeClassifier(criterion='gini')
cart.fit(X_train,y_train)

plt.figure(figsize=(20,10))
plot_tree(cart,feature_names=X_train.columns.tolist(),class_names=['1','2','3'],filled=True)

y_pred_cart = cart.predict(X_test)
cart_pred = pd.DataFrame({'Actual Class':y_test.values.flatten(),'Predicted Class':y_pred_cart.flatten()})
cart_pred

# Calculate metrics for CART decision tree
accuracy_cart = accuracy_score(y_test, y_pred_cart)
precision_cart = precision_score(y_test, y_pred_cart, average='weighted')
recall_cart = recall_score(y_test, y_pred_cart, average='weighted')
f1_cart = f1_score(y_test, y_pred_cart, average='weighted')
print("CART Decision Tree Metrics:")
print("Accuracy:", accuracy_cart)
print("Precision:", precision_cart)
print("Recall:", recall_cart)
print("F1 Score:", f1_cart)

"""## Clustering"""

!pip install scikit-learn-extra

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn.cluster import KMeans,AgglomerativeClustering,DBSCAN
from sklearn_extra.cluster import KMedoids
from sklearn.metrics import rand_score,silhouette_score,davies_bouldin_score,adjusted_rand_score
import seaborn as sns

df = pd.read_csv('Seed_Data.csv')
df

df.isna().sum()

sns.pairplot(df)

k = [3,5,7]

for i in k:
    kmeans = KMeans(n_clusters=i,random_state=0)
    kmeans.fit(df)
    df['k_means_'+str(i)] = kmeans.labels_

for i in k:
    kmedoids = KMedoids(n_clusters=i,random_state=0)
    kmedoids.fit(df)
    df['k_medoids_'+str(i)] = kmedoids.labels_

df.head(10)

print("K Means Clustering")
for i in k:
    plt.scatter(df['A'],df['P'],c=df['k_means_'+str(i)])
    plt.xlabel('Area')
    plt.ylabel('Perimeter')
    plt.title('K Means - '+str(i))
    plt.show()
    print()
    print('Silhouette Score',silhouette_score(df,df['k_means_'+str(i)]))
    print('Rand Score',rand_score(df['target'],df['k_means_'+str(i)]))
    print('Adjusted Rand Score',adjusted_rand_score(df['target'],df['k_means_'+str(i)]))
    print('Davies Bouldin Score',davies_bouldin_score(df,df['k_means_'+str(i)]))

print("K Medoids Clustering")
for i in k:
    plt.scatter(df['A'],df['P'],c=df['k_means_'+str(i)])
    plt.xlabel('Area')
    plt.ylabel('Perimeter')
    plt.title('K Medoids - '+str(i))
    plt.show()
    print()
    print('Silhouette Score',silhouette_score(df,df['k_medoids_'+str(i)]))
    print('Rand Score',rand_score(df['target'],df['k_medoids_'+str(i)]))
    print('Adjusted Rand Score',adjusted_rand_score(df['target'],df['k_medoids_'+str(i)]))
    print('Davies Bouldin Score',davies_bouldin_score(df,df['k_medoids_'+str(i)]))

"""## Hierarchial Clustering and DBSCAN"""

h = AgglomerativeClustering(n_clusters=5)
dbscan = DBSCAN(eps=0.5,min_samples=5)

df = pd.read_csv('Mall_Customers.csv')
df

X = df.iloc[:,[3,4]].values
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

h_cluster = h.fit_predict(X_scaled)
dbscan_cluster = dbscan.fit_predict(X_scaled)

print("Hierarchial Clustering")
print("Silhouette Score: ",silhouette_score(X,h_cluster))
print("Davies Bouldin Score: ",davies_bouldin_score(X,h_cluster))

print("DBSCAN Clustering")
print("Silhouette Score: ",silhouette_score(X,dbscan_cluster))
print("Davies Bouldin Score: ",davies_bouldin_score(X,dbscan_cluster))

plt.figure(figsize=(6,8))
sns.scatterplot(x=X[:,0],y=X[:,1],hue=h_cluster,palette="viridis")
plt.title("Hierarchial Clustering")
plt.xlabel("Annual Income")
plt.ylabel("Spending Score")
plt.show()

plt.figure(figsize=(6,8))
sns.scatterplot(x=X[:,0],y=X[:,-1],hue=dbscan_cluster,palette="viridis")
plt.title("DBSCAN Clustering")
plt.xlabel("Annual Income")
plt.ylabel("Spending Score")
plt.show()

"""### LAB ASSESSMENT -1"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import metrics
import statsmodels.api as sm

df = pd.read_csv('forestfires.csv')
df.head(1000)

def simple_linear_regression_fires(df):
    df = df.dropna()
    X = df[["temp"]]

    y = df["area"]
    print(y)

    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)

    model = LinearRegression()

    model.fit(X_train,y_train)

    print('Simple Linear Regression Results\n')

    print('Coefficient: ',model.coef_[0])
    print('Intercept: ',model.intercept_)

    y_pred = model.predict(X_test)

    mse = metrics.mean_squared_error(y_test, y_pred)
    r2 = metrics.r2_score(y_test, y_pred)

    print("Mean Squared Error: ", mse)
    print("r2: ",r2)

    df2 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
    print(df2)



    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    sns.scatterplot(x=X_train['temp'], y=y_train, color='blue', label='Actual')
    sns.lineplot(x=X_test['temp'], y=y_pred, color='red', label='Regression Line')
    plt.title('Scatterplot and Regression Plot')
    plt.xlabel('Temperature')
    plt.ylabel('Area')
    plt.legend()

simple_linear_regression_fires(df)

def multiple_linear_regression_fires(data):
     df = pd.read_csv(data)
     X = df[['temp', 'RH', 'wind']]
     y = df['area']

     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

     model = LinearRegression()

     model.fit(X_train, y_train)

     y_pred = model.predict(X_test)

     mse = metrics.mean_squared_error(y_test, y_pred)
     r2 = metrics.r2_score(y_test, y_pred)

     print("Multiple Linear Regression Results\n")

     print("Coefficient: ",model.coef_[0])
     print('Intercept: ',model.intercept_)

     print('Mean Squared Error: ',mse)
     print('R-squared: ',r2)

     df2 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
     print(df2)

     plt.figure(figsize=(10,14))
     sns.heatmap(df[['temp','RH','wind','area']].corr(),annot=True)

  multiple_linear_regression_fires('forestfires.csv')

"""## LAB ASSESSMENT 2"""

import pandas as pd
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import plot_tree
from sklearn.tree import export_text

df = pd.read_csv('train.csv')
df_test = pd.read_csv('test.csv')

#Remove missing values

df = df.dropna()
df.isna()

# Encoding categorical variables

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['Sex'] = le.fit_transform(df['Sex'])
df['Ticket'] = le.fit_transform(df['Ticket'])
df['Cabin'] = le.fit_transform(df['Cabin'])
df['Embarked'] = le.fit_transform(df['Embarked'])


df.head(100)

sns.pairplot(data=df,hue='Survived')

# Preparing the testing dataset

#df_test = df_test.drop(columns = ['Cabin'])
df_test = df_test.dropna()
df_test['Cabin'] = le.fit_transform(df_test['Cabin'])

df_test['Sex'] = le.fit_transform(df_test['Sex'])
df_test['Ticket'] = le.fit_transform(df_test['Ticket'])
df_test['Embarked'] = le.fit_transform(df_test['Embarked'])

X_train = df.drop(columns = ['Survived','Name'])
y_train = df['Survived']


X_test = df_test.drop(columns = ['Survived','Name'])
y_test = df_test['Survived']

clf = DecisionTreeClassifier(criterion='entropy', random_state=42)
clf.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
y_pred = clf.predict(X_test)

# Calculate metrics for ID3 decision tree
accuracy_id3 = accuracy_score(y_test, y_pred)
precision_id3 = precision_score(y_test, y_pred, average='weighted')
recall_id3 = recall_score(y_test, y_pred, average='weighted')
f1_id3 = f1_score(y_test, y_pred, average='weighted')

print("Decision Tree Metrics:")
print("Accuracy:", accuracy_id3)
print("Precision:", precision_id3)
print("Recall:", recall_id3)
print("F1 Score:", f1_id3)

# Visualize the decision tree using text representation
tree_rules = export_text(clf, feature_names=X_train.columns.tolist())
print(tree_rules)


# Visualize the decision tree
plt.figure(figsize=(40, 20))
plot_tree(clf, feature_names=X_train.columns.tolist(), class_names=['0','1'], filled=True) #Here class names are the possible values of Survived column that is either 0 (not survived) or 1(survived)

"""## LAB - 1"""

import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt
from geopandas import GeoDataFrame
import geopandas as gpd
from shapely.geometry import Point
import folium

file="Bias_correction_ucl.csv"
df = pd.read_csv(file)

def dataexplore():
    file="Bias_correction_ucl.csv"
    df = pd.read_csv(file)
    print("1. Load Data")
    print("2. Display the dimension, shape, size and attributes type")
    print("3. Display the first few rows")
    print("4. Provide summary statistics for key features.")
    print("5. Identify and handle any missing values or outliers.")
    choice = int(input("Enter your choice: "))
    if choice == 1:
        df = pd.read_csv(file)
    elif choice == 2:
        print("Size: ",df.size)
        print("Shape: ",df.shape)
        print("Dimension: ",df.ndim)
        print("Attributes: ",df.dtypes)
    elif choice == 3:
        print(df.head(10))
    elif choice == 4:
        print(df.describe())
    elif choice == 5:
        print("Before Dropping Missing Values")
        df_copy = df
        print(df)
        print("After Dropping Missing Values")
        df_copy.dropna()
        print(df_copy)
    else:
        print("Invalid Choice")

def temporalanalysis():
    file="Bias_correction_ucl.csv"
    df = pd.read_csv(file)
    print("1. Explore the temporal aspect of the dataset. Are there any trends or patterns over time?")
    print("2. Visualize the variation in temperature (Present_Tmax and Present_Tmin) over different years.")
    ch = int(input("Enter your choice: "))
    if ch == 1:
       print(df[["Present_Tmax","Present_Tmin"]])
    elif ch == 2:
        df['Date'] = pd.to_datetime(df['Date'])
        df.set_index('Date', inplace=True)
        plt.figure(figsize=(12, 6))
        sn.lineplot(data=df[['Present_Tmax', 'Present_Tmin']])
        plt.title('Temperature Variation Over Time')
        plt.xlabel('Year')
        plt.ylabel('Temperature (°C)')
        plt.show()

def geographicalanalysis():
    file="Bias_correction_ucl.csv"
    df = pd.read_csv(file)
    print("1. Explore the geographical features (lat, lon, DEM, Slope).")
    print("2. Visualize the distribution of weather stations on a map. ")
    print("3. Analyze how elevation (DEM) and slope impact temperature.")
    print("4. Enter your choice: ")
    choice = int(input("Enter your choice: "))
    if choice == 1:
        plt.figure(figsize=(12, 6))
        sn.pairplot(df[['lat', 'lon', 'DEM', 'Slope']])
        plt.suptitle('Geographical Features Analysis')
        plt.show()
    elif choice ==2:
        station_map = folium.Map(location=[df['lat'].mean(), df['lon'].mean()], zoom_start=12)
        for index, row in df.iterrows():
            folium.Marker([row['lat'], row['lon']], popup=f"Station {row['station']}").add_to(station_map)
        station_map.save('weather_stations_map.html')
    elif choice == 3:
        plt.figure(figsize=(12, 6))
        df_no_duplicates = df[['DEM', 'Present_Tmax', 'Present_Tmin']].drop_duplicates(subset='DEM')
        sn.scatterplot(x='DEM', y='Present_Tmax', data=df_no_duplicates, label='Present_Tmax')
        sn.scatterplot(x='DEM', y='Present_Tmin', data=df_no_duplicates, label='Present_Tmin')
        plt.title('Impact of Elevation on Temperature')
        plt.xlabel('Elevation (m)')
        plt.ylabel('Temperature (°C)')
        plt.legend()
        plt.show()
    else:
        print("Invalid Choice")

def correlationanalysis():
    file="Bias_correction_ucl.csv"
    df = pd.read_csv(file)
    df['Date'] = pd.to_datetime(df['Date'])
    df.set_index('Date', inplace=True)
    print("1. Calculate and visualize the correlation matrix for numerical features.")
    print("2. Identify highly correlated features.")
    choice = int(input("Enter a choice: "))
    if choice == 1:
        correlation_matrix = df.corr()
        plt.figure(figsize=(12, 8))
        sn.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
        plt.title('Correlation Matrix')
        plt.show()
    elif choice == 2:
        correlation_matrix = df.corr()
        highly_correlated = correlation_matrix[(correlation_matrix.abs() > 0.7) & (correlation_matrix < 1.0)].dropna(how='all', axis=1)
        print("Highly correlated features:")
        print(highly_correlated)

        df_reset = df.reset_index()
        plt.figure(figsize=(10, 6))
        sn.scatterplot(x='Present_Tmin', y='LDAPS_Tmin_lapse', data=df_reset)
        plt.title('Scatter Plot: Present_Tmin vs LDAPS_Tmin_lapse')
        plt.xlabel('Present_Tmin (°C)')
        plt.ylabel('LDAPS_Tmin_lapse (°C)')
        plt.show()
        plt.figure(figsize=(10, 6))
        sn.scatterplot(x='LDAPS_Tmax_lapse', y='Next_Tmax', data=df_reset)
        plt.title('Scatter Plot: LDAPS_Tmax_lapse vs Next_Tmax')
        plt.xlabel('LDAPS_Tmax_lapse (°C)')
        plt.ylabel('Next_Tmax (°C)')
        plt.show()
    else:
        print("Invalid Choice")

def featurespecificanalysis():
    print("1. Explore the LDAPS features (RH, Tmax_lapse, Tmin_lapse, WS, LH, CC, PPT).")
    print("2. Visualize the relationships between LDAPS features and other key variables.")
    print("3. Analyze the impact of cloud cover and precipitation on temperature.")
    print("4. Plot the individual box plot for all attributes except the date attribute")
    choice = int(input())
    if choice == 1:
        ldaps_features = df[['LDAPS_RHmin', 'LDAPS_RHmax', 'LDAPS_Tmax_lapse', 'LDAPS_Tmin_lapse', 'LDAPS_WS', 'LDAPS_LH',
                             'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4', 'LDAPS_PPT1', 'LDAPS_PPT2', 'LDAPS_PPT3', 'LDAPS_PPT4']]

        plt.figure(figsize=(14, 10))
        sn.heatmap(ldaps_features.corr(), annot=True, cmap='coolwarm', fmt=".2f")
        plt.title('Correlation Matrix of LDAPS Features')
        plt.show()
    elif choice == 2:
        plt.figure(figsize=(14, 6))
        sn.boxplot(x='LDAPS_CC1', y='Present_Tmax', data=df)
        plt.title('Impact of LDAPS_CC1 on Present_Tmax')
        plt.xlabel('LDAPS_CC1')
        plt.ylabel('Present_Tmax (°C)')
        plt.show()
    elif choice == 3:
        plt.figure(figsize=(14, 6))
        sn.boxplot(x='LDAPS_PPT1', y='Present_Tmax', data=df)
        plt.title('Impact of LDAPS_PPT1 on Present_Tmax')
        plt.xlabel('LDAPS_PPT1')
        plt.ylabel('Present_Tmax (°C)')
        plt.show()

    elif choice == 4:
        attributes_to_plot = df.columns.difference(['Date'])
        plt.figure(figsize=(18, 12))
        sn.boxplot(data=df[attributes_to_plot])
        plt.title('Box Plots of Attributes')
        plt.xticks(rotation=45, ha='right')
        plt.show()
    else:
        print("Invalid Choice")

while True:
    print("1. Data Exploration")
    print("2. Temporal Analysis")
    print("3. Geographical Analysis")
    print("4. Correlation Analysis")
    print("5. Feature-specific Analysis")
    print("6. Exit")
    choice = int(input("Enter your choice: "))
    if choice == 1:
        dataexplore()
    elif choice ==2:
        temporalanalysis()
    elif choice ==3:
        geographicalanalysis()
    elif choice == 4:
        correlationanalysis()
    elif choice ==5:
        featurespecificanalysis()
    elif choice == 6:
        break